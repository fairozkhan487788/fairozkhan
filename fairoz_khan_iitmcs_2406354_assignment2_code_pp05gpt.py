# -*- coding: utf-8 -*-
"""Fairoz_Khan_IITMCS_2406354_Assignment2_Code_PP05gpt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rQ6euHj2be7HphQx89Ds_MLUcC8uM6s_

# CIFAR-10 Autoencoders: AE and DAE
## Deep Learning and Applications Assignment-2 | Part-1
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import numpy as np
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr

# Set seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load CIFAR-10 dataset
transform = transforms.ToTensor()
train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
train_set, val_set = random_split(train_set, [45000, 5000])
train_loader = DataLoader(train_set, batch_size=128, shuffle=True)
val_loader = DataLoader(val_set, batch_size=128, shuffle=False)
test_loader = DataLoader(test_set, batch_size=128, shuffle=False)

# Define improved Autoencoder architecture
class Autoencoder(nn.Module):
    def __init__(self, latent_dim=512):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(256 * 4 * 4, latent_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 256 * 4 * 4),
            nn.ReLU(),
            nn.Unflatten(1, (256, 4, 4)),
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, 4, 2, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        latent = self.encoder(x)
        out = self.decoder(latent)
        return out, latent

# Xavier initialization for reproducibility
def init_weights(m):
    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):
        nn.init.xavier_uniform_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

# Training function
def train_autoencoder(model, train_loader, val_loader, epochs=50, noise_std=0):
    model.apply(init_weights)
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)
    criterion = nn.MSELoss()
    history = []
    best_loss = float('inf')
    best_model = None

    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for x, _ in train_loader:
            x = x.to(device)
            x_noisy = torch.clamp(x + noise_std * torch.randn_like(x), 0., 1.) if noise_std > 0 else x
            optimizer.zero_grad()
            outputs, _ = model(x_noisy)
            loss = criterion(outputs, x)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        val_loss = 0
        model.eval()
        with torch.no_grad():
            for x, _ in val_loader:
                x = x.to(device)
                x_noisy = torch.clamp(x + noise_std * torch.randn_like(x), 0., 1.) if noise_std > 0 else x
                outputs, _ = model(x_noisy)
                loss = criterion(outputs, x)
                val_loss += loss.item()

        avg_train = train_loss / len(train_loader)
        avg_val = val_loss / len(val_loader)
        history.append(avg_val)
        scheduler.step()

        if avg_val < best_loss:
            best_loss = avg_val
            best_model = model.state_dict()

        print(f"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f}")

    print(f"Best Val Loss: {best_loss:.4f}")
    model.load_state_dict(best_model)
    return history

# Evaluation metrics
def evaluate_model(model, dataloader):
    model.eval()
    total_ssim, total_psnr, total_mae, total_mse = 0, 0, 0, 0
    with torch.no_grad():
        for x, _ in dataloader:
            x = x.to(device)
            outputs, _ = model(x)
            x = x.cpu().numpy()
            outputs = outputs.cpu().numpy()
            for i in range(len(x)):
                orig = np.transpose(x[i], (1,2,0))
                recon = np.transpose(outputs[i], (1,2,0))
                total_ssim += ssim(orig, recon, channel_axis=2, data_range=1.0)
                total_psnr += psnr(orig, recon, data_range=1.0)
                total_mae += np.mean(np.abs(orig - recon))
                total_mse += np.mean((orig - recon) ** 2)
    n = len(dataloader.dataset)
    print(f"SSIM: {total_ssim/n:.4f}, PSNR: {total_psnr/n:.2f} dB, MAE: {total_mae/n:.4f}, MSE: {total_mse/n:.6f}")

# Visualization
def visualize_reconstructions(model, dataloader, noise_std=0):
    model.eval()
    x, _ = next(iter(dataloader))
    x = x[:8].to(device)
    x_noisy = torch.clamp(x + noise_std * torch.randn_like(x), 0., 1.) if noise_std > 0 else x
    with torch.no_grad():
        recon, _ = model(x_noisy)
    x = x.cpu().numpy()
    x_noisy = x_noisy.cpu().numpy()
    recon = recon.cpu().numpy()
    fig, axs = plt.subplots(3, 8, figsize=(16, 6))
    for i in range(8):
        axs[0, i].imshow(np.transpose(x[i], (1,2,0)))
        axs[0, i].axis('off')
        axs[1, i].imshow(np.transpose(x_noisy[i], (1,2,0)))
        axs[1, i].axis('off')
        axs[2, i].imshow(np.transpose(recon[i], (1,2,0)))
        axs[2, i].axis('off')
    plt.suptitle("Top: Original | Middle: Noisy | Bottom: Reconstructed")
    plt.tight_layout()
    plt.show()

# Visualize latent space
def visualize_latent_space(model, dataloader):
    model.eval()
    all_latents = []
    labels = []
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(device)
            _, latent = model(x)
            all_latents.append(latent.cpu())
            labels.extend(y)
    X = torch.cat(all_latents).numpy()
    y = np.array(labels)
    X_tsne = TSNE(n_components=2, perplexity=30).fit_transform(X)
    X_pca = PCA(n_components=2).fit_transform(X)

    plt.figure(figsize=(14,6))
    plt.subplot(1,2,1)
    scatter = plt.scatter(X_tsne[:,0], X_tsne[:,1], c=y, cmap='tab10', s=10)
    plt.legend(*scatter.legend_elements(), title="Classes")
    plt.title("Latent Space (t-SNE)")

    plt.subplot(1,2,2)
    scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=y, cmap='tab10', s=10)
    plt.title("Latent Space (PCA)")
    plt.show()

# --- Train AE ---
print("Training Standard Autoencoder (AE)...")
ae = Autoencoder()
hist_ae = train_autoencoder(ae, train_loader, val_loader)
visualize_reconstructions(ae, test_loader)
evaluate_model(ae, test_loader)
visualize_latent_space(ae, test_loader)

# --- Train DAE for different σ ---
for sigma in [0.1, 0.3, 0.5]:
    print(f"\nTraining Denoising Autoencoder (DAE) with σ={sigma}...")
    dae = Autoencoder()
    hist_dae = train_autoencoder(dae, train_loader, val_loader, epochs=30, noise_std=sigma)
    visualize_reconstructions(dae, test_loader, noise_std=sigma)
    evaluate_model(dae, test_loader)
    visualize_latent_space(dae, test_loader)
    plt.plot(hist_ae, label='AE')
    plt.plot(hist_dae, label=f'DAE (σ={sigma})')
    plt.xlabel('Epochs')
    plt.ylabel('Val MSE Loss')
    plt.title('AE vs DAE Loss Curve')
    plt.legend()
    plt.show()

"""# PART-II: Variational Autoencoder (VAE) & Latent Space Inference
## Model-2: Variational Autoencoder (VAE)

"""

# VAE model
class VAE(nn.Module):
    def __init__(self, latent_dim=128):
        super(VAE, self).__init__()
        self.latent_dim = latent_dim
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.ReLU(),
            nn.Flatten()
        )
        self.fc_mu = nn.Linear(256*4*4, latent_dim)
        self.fc_logvar = nn.Linear(256*4*4, latent_dim)
        self.decoder_fc = nn.Linear(latent_dim, 256*4*4)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, 4, 2, 1),
            nn.Sigmoid()
        )

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        z = self.reparameterize(mu, logvar)
        h_dec = self.decoder_fc(z).view(-1, 256, 4, 4)
        out = self.decoder(h_dec)
        return out, mu, logvar, z

# Loss Function
def vae_loss(x, recon, mu, logvar):
    recon_loss = F.mse_loss(recon, x, reduction='sum')
    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return recon_loss + kl, recon_loss, kl

# Train VAE
def train_vae(model, loader, epochs=30):
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    recon_losses, kl_losses = [], []

    for epoch in range(epochs):
        model.train()
        total_recon, total_kl = 0, 0
        for x, _ in loader:
            x = x.to(device)
            optimizer.zero_grad()
            recon, mu, logvar, _ = model(x)
            loss, recon_loss, kl = vae_loss(x, recon, mu, logvar)
            loss.backward()
            optimizer.step()
            total_recon += recon_loss.item()
            total_kl += kl.item()
        avg_recon = total_recon / len(loader.dataset)
        avg_kl = total_kl / len(loader.dataset)
        recon_losses.append(avg_recon)
        kl_losses.append(avg_kl)
        print(f"Epoch {epoch+1}/{epochs}, Recon Loss: {avg_recon:.4f}, KL Loss: {avg_kl:.4f}")

    return recon_losses, kl_losses

# Evaluation

def evaluate_model(model, dataloader):
    model.eval()
    total_ssim, total_psnr, total_mae, total_mse = 0, 0, 0, 0
    with torch.no_grad():
        for x, _ in dataloader:
            x = x.to(device)
            recon, _, _, _ = model(x)
            x = x.cpu().numpy()
            recon = recon.cpu().numpy()
            for i in range(len(x)):
                orig = np.transpose(x[i], (1,2,0))
                recon_img = np.transpose(recon[i], (1,2,0))
                total_ssim += ssim(orig, recon_img, channel_axis=2, data_range=1.0)
                total_psnr += psnr(orig, recon_img, data_range=1.0)
                total_mae += np.mean(np.abs(orig - recon_img))
                total_mse += np.mean((orig - recon_img) ** 2)
    n = len(dataloader.dataset)
    print(f"SSIM: {total_ssim/n:.4f}, PSNR: {total_psnr/n:.2f}, MAE: {total_mae/n:.4f}, MSE: {total_mse/n:.6f}")

# Latent Interpolation

def interpolate(model, data):
    model.eval()
    x, _ = next(iter(data))
    x = x[:2].to(device)
    with torch.no_grad():
        _, _, _, z = model(x)
    z1, z2 = z[0], z[1]
    interps = []
    for alpha in np.linspace(0, 1, 10):
        z_interp = (1 - alpha) * z1 + alpha * z2
        z_interp = z_interp.unsqueeze(0)
        recon = model.decoder(model.decoder_fc(z_interp).view(-1, 256, 4, 4))
        interps.append(recon.detach().cpu().squeeze().permute(1, 2, 0).numpy())
    fig, axs = plt.subplots(1, 10, figsize=(15,2))
    for i, img in enumerate(interps):
        axs[i].imshow(img)
        axs[i].axis('off')
    plt.suptitle("Latent Interpolation")
    plt.show()

# Latent Arithmetic
def latent_arithmetic(model, loader):
    model.eval()
    x, y = next(iter(loader))
    label_map = {v: k for k, v in loader.dataset.class_to_idx.items()}
    targets = {"cat": 3, "dog": 5, "bird": 2}
    images = {name: x[y == idx][0].unsqueeze(0).to(device) for name, idx in targets.items()}
    with torch.no_grad():
        _, _, _, z_cat = model(images["cat"])
        _, _, _, z_dog = model(images["dog"])
        _, _, _, z_bird = model(images["bird"])
        z_result = z_dog - z_cat + z_bird
        recon = model.decoder(model.decoder_fc(z_result).view(-1, 256, 4, 4))
    img = recon.cpu().squeeze().permute(1,2,0).numpy()
    plt.imshow(img)
    plt.title("Latent Arithmetic: dog - cat + bird")
    plt.axis('off')
    plt.show()

# Latent Space Visualization
def visualize_latent_space(model, loader):
    model.eval()
    zs, labels = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            _, _, _, z = model(x)
            zs.append(z.cpu().numpy())
            labels.append(y.numpy())
    zs = np.concatenate(zs, axis=0)
    labels = np.concatenate(labels, axis=0)
    # Reduce with PCA
    pca = PCA(n_components=2)
    z_pca = pca.fit_transform(zs)
    plt.figure(figsize=(8, 6))
    scatter = plt.scatter(z_pca[:, 0], z_pca[:, 1], c=labels, cmap='tab10', s=5)
    plt.colorbar(scatter, ticks=range(10))
    plt.title("Latent Space PCA Visualization")
    plt.xlabel("PCA 1")
    plt.ylabel("PCA 2")
    plt.grid(True)
    plt.show()

# Instantiate and run
vae = VAE()
recon_losses, kl_losses = train_vae(vae, train_loader)
plt.plot(recon_losses, label='Reconstruction Loss')
plt.plot(kl_losses, label='KL Divergence Loss')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("VAE Training Losses")
plt.legend()
plt.show()

evaluate_model(vae, test_loader)
interpolate(vae, test_loader)
latent_arithmetic(vae, test_loader)
visualize_latent_space(vae, test_loader)

"""# PART - III  
## CIFAR-10 Masked Convolutional Autoencoder (MCAE)
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Masked Autoencoder with CNN
class MCAE(nn.Module):
    def __init__(self, mask_ratio=0.25):
        super(MCAE, self).__init__()
        self.mask_ratio = mask_ratio

        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, 2, 1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, 2, 1),
            nn.ReLU()
        )

        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(64, 3, 3, 1, 1),
            nn.Sigmoid()
        )

    def mask_feature_map(self, x):
        B, C, H, W = x.shape
        total_patches = H * W
        num_mask = int(self.mask_ratio * total_patches)
        for b in range(B):
            indices = torch.randperm(total_patches)[:num_mask]
            x[b].view(C, -1)[:, indices] = 0
        return x

    def forward(self, x):
        encoded = self.encoder(x)
        masked = self.mask_feature_map(encoded.clone())
        decoded = self.decoder(masked)
        return decoded, encoded.view(encoded.size(0), -1)

# Train MCAE

def train_mcae(model, loader, epochs=30):
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    loss_history = []
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for x, _ in loader:
            x = x.to(device)
            optimizer.zero_grad()
            recon, _ = model(x)
            loss = F.mse_loss(recon, x)
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * x.size(0)
        avg_loss = total_loss / len(loader.dataset)
        loss_history.append(avg_loss)
        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")
    return loss_history

# Evaluate MCAE Reconstruction

def evaluate_mcae(model, loader):
    model.eval()
    with torch.no_grad():
        for x, _ in loader:
            x = x.to(device)
            recon, _ = model(x)
            break
    x = x.cpu()
    recon = recon.cpu()
    fig, axs = plt.subplots(2, 10, figsize=(15, 4))
    for i in range(10):
        axs[0, i].imshow(np.transpose(x[i], (1, 2, 0)))
        axs[0, i].axis('off')
        axs[1, i].imshow(np.transpose(recon[i], (1, 2, 0)))
        axs[1, i].axis('off')
    plt.suptitle("Original vs Reconstructed (MCAE)")
    plt.show()

# Extract features and evaluate linear classifier

def evaluate_feature_extraction(model, loader):
    model.eval()
    features, labels = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            _, feat = model(x)
            features.append(feat.cpu().numpy())
            labels.append(y.numpy())
    features = np.concatenate(features)
    labels = np.concatenate(labels)
    return features, labels

# Visualize latent space using PCA and t-SNE

def visualize_latent_space(model, loader):
    model.eval()
    zs, labels = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            _, z = model(x)
            zs.append(z.cpu().numpy())
            labels.append(y.numpy())
    zs = np.concatenate(zs, axis=0)
    labels = np.concatenate(labels, axis=0)

    # PCA
    pca = PCA(n_components=2)
    z_pca = pca.fit_transform(zs)

    # t-SNE
    tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)
    z_tsne = tsne.fit_transform(zs)

    # Side-by-side plot
    fig, axs = plt.subplots(1, 2, figsize=(14, 6))
    sc1 = axs[0].scatter(z_pca[:, 0], z_pca[:, 1], c=labels, cmap='tab10', s=5)
    axs[0].set_title("Latent Space PCA")
    axs[0].set_xlabel("PCA 1")
    axs[0].set_ylabel("PCA 2")
    axs[0].grid(True)

    sc2 = axs[1].scatter(z_tsne[:, 0], z_tsne[:, 1], c=labels, cmap='tab10', s=5)
    axs[1].set_title("Latent Space t-SNE")
    axs[1].set_xlabel("t-SNE 1")
    axs[1].set_ylabel("t-SNE 2")
    axs[1].grid(True)

    cbar = fig.colorbar(sc2, ax=axs, ticks=range(10), location='right')
    cbar.set_label('Class Labels')
    plt.suptitle("Latent Space Visualization: PCA vs t-SNE")
    plt.tight_layout()
    plt.show()

# Instantiate and run
mcae = MCAE(mask_ratio=0.25)
losses = train_mcae(mcae, train_loader)
plt.plot(losses)
plt.title("MCAE Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

evaluate_mcae(mcae, test_loader)

train_features, train_labels = evaluate_feature_extraction(mcae, train_loader)
test_features, test_labels = evaluate_feature_extraction(mcae, test_loader)

clf = LogisticRegression(max_iter=1000)
clf.fit(train_features, train_labels)
pred = clf.predict(test_features)
acc = accuracy_score(test_labels, pred)
print(f"Linear Classification Accuracy (Frozen Features): {acc * 100:.2f}%")

# Instantiate and run
mcae = MCAE(mask_ratio=0.25)
losses = train_mcae(mcae, train_loader)
plt.plot(losses)
plt.title("MCAE Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

evaluate_mcae(mcae, test_loader)

train_features, train_labels = evaluate_feature_extraction(mcae, train_loader)
test_features, test_labels = evaluate_feature_extraction(mcae, test_loader)

clf = LogisticRegression(max_iter=1000)
clf.fit(train_features, train_labels)
pred = clf.predict(test_features)
acc = accuracy_score(test_labels, pred)
print(f"Linear Classification Accuracy (Frozen Features): {acc * 100:.2f}%")

visualize_latent_space(mcae, test_loader)





